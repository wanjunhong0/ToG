{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import argparse\n",
    "from utils import prepare_dataset, run_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--dataset\", type=str,\n",
    "                    default=\"webqsp\", help=\"choose the dataset.\")\n",
    "parser.add_argument(\"--max_length\", type=int,\n",
    "                    default=256, help=\"the max length of LLMs output.\")\n",
    "parser.add_argument(\"--LLM_type\", type=str,\n",
    "                    default=\"llama\", help=\"base LLM model.\")\n",
    "parser.add_argument(\"--openai_api_keys\", type=str,\n",
    "                    default=\"\", help=\"if the LLM_type is gpt-3.5-turbo or gpt-4, you need add your own openai api keys.\")\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Running ToG on webqsp dataset.\n"
     ]
    }
   ],
   "source": [
    "datas, question_string = prepare_dataset(args.dataset)\n",
    "print(\"Start Running ToG on %s dataset.\" % args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_prompt = \"\"\"Given a quesion, please extract any useful information about the topic of the given question.\n",
    "quesion: {}\n",
    "topic: {}\n",
    "information:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_prompt = \"\"\"Given the background information of the topic, please the answer the question related to the topic.\n",
    "quesion: {}\n",
    "topic: {}\n",
    "information: {}\n",
    "answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1639/1639 [6:04:22<00:00, 13.34s/it]  \n"
     ]
    }
   ],
   "source": [
    "# datas = datas[:2]\n",
    "for data in tqdm(datas):\n",
    "    question = data[question_string]\n",
    "    topic_entity = data['topic_entity']\n",
    "    topic = str(list(topic_entity.values())).strip('[]').replace(\"'\", \"\")\n",
    "    prompt = run_llm(topic_prompt.format(question, topic), 0., args.max_length*2, args.openai_api_keys, args.LLM_type)\n",
    "    response = run_llm(question_prompt.format(question, topic, prompt), 0., args.max_length, args.openai_api_keys, args.LLM_type)\n",
    "    dict = {\"question\": question, \"result\": response, 'prompt': prompt}\n",
    "    with open(\"topic_{}_{}.jsonl\".format(args.LLM_type, args.dataset), \"a\") as outfile:\n",
    "        json_str = json.dumps(dict)\n",
    "        outfile.write(json_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
